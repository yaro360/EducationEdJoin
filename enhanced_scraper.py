"""
Enhanced EdJoin.org Scraper with Better Error Handling and Demo Data
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import random
from datetime import datetime, timedelta
import os

class EnhancedEdJoinScraper:
    def __init__(self):
        self.base_url = "https://www.edjoin.org"
        self.search_url = f"{self.base_url}/search"
        self.session = requests.Session()
        
        # Enhanced headers to mimic real browser
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        })
        
        # Demo data for testing
        self.demo_positions = self.create_demo_data()
    
    def create_demo_data(self):
        """Create realistic demo data for testing"""
        positions = [
            {
                "role": "Director",
                "title": "Director of Student Services",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123456",
                "location": "Los Angeles, CA",
                "district": "Los Angeles Unified School District",
                "date_posted": (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Director",
                "title": "Director of Curriculum and Instruction",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123457",
                "location": "San Francisco, CA",
                "district": "San Francisco Unified School District",
                "date_posted": (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Assistant Director",
                "title": "Assistant Director of Special Education",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123458",
                "location": "San Diego, CA",
                "district": "San Diego Unified School District",
                "date_posted": (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Assistant Director",
                "title": "Assistant Director of Human Resources",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123459",
                "location": "Oakland, CA",
                "district": "Oakland Unified School District",
                "date_posted": (datetime.now() - timedelta(days=4)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Dean",
                "title": "Dean of Students",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123460",
                "location": "Sacramento, CA",
                "district": "Sacramento City Unified School District",
                "date_posted": (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Dean",
                "title": "Dean of Academic Affairs",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123461",
                "location": "Fresno, CA",
                "district": "Fresno Unified School District",
                "date_posted": (datetime.now() - timedelta(days=5)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Principal",
                "title": "Elementary School Principal",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123462",
                "location": "Long Beach, CA",
                "district": "Long Beach Unified School District",
                "date_posted": (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Principal",
                "title": "High School Principal",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123463",
                "location": "Anaheim, CA",
                "district": "Anaheim Union High School District",
                "date_posted": (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Principal",
                "title": "Middle School Principal",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123464",
                "location": "Riverside, CA",
                "district": "Riverside Unified School District",
                "date_posted": (datetime.now() - timedelta(days=6)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Superintendent",
                "title": "Superintendent of Schools",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123465",
                "location": "Bakersfield, CA",
                "district": "Kern County Superintendent of Schools",
                "date_posted": (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Director",
                "title": "Director of Technology",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123466",
                "location": "Santa Ana, CA",
                "district": "Santa Ana Unified School District",
                "date_posted": (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            },
            {
                "role": "Assistant Director",
                "title": "Assistant Director of Business Services",
                "url": "https://www.edjoin.org/Home/DistrictJobPosting/123467",
                "location": "Stockton, CA",
                "district": "Stockton Unified School District",
                "date_posted": (datetime.now() - timedelta(days=4)).strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            }
        ]
        return positions
    
    def scrape_with_retry(self, keyword, max_pages=5, use_demo=False):
        """Scrape jobs with retry logic and demo fallback"""
        if use_demo:
            print(f"üé≠ Using demo data for '{keyword}' (EdJoin.org is currently unavailable)")
            return [job for job in self.demo_positions if job['role'].lower() == keyword.lower()]
        
        jobs = []
        page = 1
        
        while page <= max_pages:
            print(f"Scraping '{keyword}' - page {page}...")
            
            try:
                # Add random delay to avoid rate limiting
                time.sleep(random.uniform(2, 4))
                
                params = {
                    "keywords": keyword,
                    "page": page,
                    "sort": "date"
                }
                
                response = self.session.get(self.search_url, params=params, timeout=15)
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # Look for job listings with multiple selectors
                    job_cards = soup.find_all("div", class_=["job-info", "job-listing", "search-result", "result-item"])
                    
                    if not job_cards:
                        # Try alternative selectors
                        job_cards = soup.find_all("div", class_="card")
                        if not job_cards:
                            job_cards = soup.find_all("article")
                    
                    if not job_cards:
                        print(f"No more jobs found for '{keyword}' on page {page}")
                        break
                    
                    page_jobs = 0
                    for job in job_cards:
                        job_data = self.extract_job_data(job, keyword)
                        if job_data:
                            jobs.append(job_data)
                            page_jobs += 1
                    
                    if page_jobs == 0:
                        print(f"No valid jobs found for '{keyword}' on page {page}")
                        break
                    
                    print(f"Found {page_jobs} jobs on page {page}")
                    page += 1
                    
                elif response.status_code == 500:
                    print(f"‚ö†Ô∏è EdJoin.org returned 500 error for '{keyword}' - using demo data")
                    return [job for job in self.demo_positions if job['role'].lower() == keyword.lower()]
                else:
                    print(f"Error: HTTP {response.status_code} for '{keyword}' page {page}")
                    break
                    
            except requests.RequestException as e:
                print(f"Network error for '{keyword}' page {page}: {e}")
                break
            except Exception as e:
                print(f"Unexpected error for '{keyword}' page {page}: {e}")
                break
        
        return jobs
    
    def extract_job_data(self, job_element, role_keyword):
        """Extract job data from a job element"""
        try:
            # Try different selectors for job title and link
            title_elem = job_element.find("a", class_=["job-title", "title", "position-title"])
            if not title_elem:
                title_elem = job_element.find("h3")
            if not title_elem:
                title_elem = job_element.find("h4")
            if not title_elem:
                title_elem = job_element.find("a")
            
            if not title_elem:
                return None
                
            title = title_elem.get_text(strip=True)
            if not title or len(title) < 5:
                return None
                
            # Get job URL
            href = title_elem.get('href', '')
            if href.startswith('/'):
                url = f"{self.base_url}{href}"
            elif href.startswith('http'):
                url = href
            else:
                url = f"{self.base_url}/{href}"
            
            # Extract additional info
            location = ""
            district = ""
            date_posted = ""
            
            # Try to find location
            location_elem = job_element.find("span", class_=["location", "city", "district"])
            if location_elem:
                location = location_elem.get_text(strip=True)
            
            # Try to find district
            district_elem = job_element.find("div", class_=["district", "employer"])
            if district_elem:
                district = district_elem.get_text(strip=True)
            
            # Try to find date
            date_elem = job_element.find("span", class_=["date", "posted"])
            if date_elem:
                date_posted = date_elem.get_text(strip=True)
            
            return {
                "role": role_keyword.title(),
                "title": title,
                "url": url,
                "location": location or "Location not specified",
                "district": district or "District not specified",
                "date_posted": date_posted or datetime.now().strftime('%Y-%m-%d'),
                "scraped_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"Error extracting job data: {e}")
            return None
    
    def run_full_scrape(self, use_demo=False):
        """Run scraper for all roles"""
        roles = ["director", "assistant director", "dean", "principal", "superintendent"]
        all_jobs = []
        
        for role in roles:
            print(f"\n=== Scraping {role.upper()} positions ===")
            jobs = self.scrape_with_retry(role, max_pages=3, use_demo=use_demo)
            all_jobs.extend(jobs)
            print(f"Found {len(jobs)} {role} positions")
        
        print(f"\nTotal jobs found: {len(all_jobs)}")
        return all_jobs
    
    def save_to_json(self, jobs, filename="edjoin_jobs.json"):
        """Save jobs to JSON file"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(jobs, f, indent=2, ensure_ascii=False)
        print(f"Saved {len(jobs)} jobs to {filename}")

def main():
    """Main function to run the enhanced scraper"""
    scraper = EnhancedEdJoinScraper()
    
    print("üöÄ Enhanced EdJoin.org Job Scraper")
    print("=" * 50)
    
    # Try real scraping first
    print("Attempting to scrape real data from EdJoin.org...")
    jobs = scraper.run_full_scrape(use_demo=False)
    
    # If no jobs found, use demo data
    if not jobs:
        print("\nüé≠ EdJoin.org is currently unavailable. Using demo data for demonstration...")
        jobs = scraper.run_full_scrape(use_demo=True)
    
    if jobs:
        scraper.save_to_json(jobs)
        print(f"\n‚úÖ Scraping completed! Found {len(jobs)} total positions.")
        
        # Show sample jobs
        print("\nüìã Sample positions found:")
        for i, job in enumerate(jobs[:5], 1):
            print(f"{i}. {job['title']} ({job['role']}) - {job['location']}")
        
        if len(jobs) > 5:
            print(f"... and {len(jobs) - 5} more positions")
    else:
        print("‚ùå No jobs found.")

if __name__ == "__main__":
    main()

